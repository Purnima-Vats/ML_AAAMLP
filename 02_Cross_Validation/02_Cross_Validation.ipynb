{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642f37f6",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "- Cross-validation is dividing training data into a few parts. We train the model on\n",
    "some of these parts and test on the remaining parts\n",
    "- Choosing the right cross-validation depends on the dataset you are dealing with, and one‚Äôs choice of cross-validation on one dataset may or may not apply to other datasets.\n",
    "- Some most popular and widely used cross-validation techniques are as follows:\n",
    "    1. k-fold\n",
    "    2. stratified k-fold\n",
    "    3. hold-out based \n",
    "    4. leave-one-out \n",
    "    5. group k-fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2a3c7",
   "metadata": {},
   "source": [
    "### 1. k-fold\n",
    "\n",
    "- When you get a dataset to build machine learning models, you separate them into two different sets: training and validation.\n",
    "- We can divide the data into k different sets which are exclusive of each other. This\n",
    "is known as k-fold cross-validation.\n",
    "- You can use this process with almost all kinds of datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f6de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and model_selection module of scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ada65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df50fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c03fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new folder kfold and fill it with -1\n",
    "df[\"kfold\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443f275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the rows of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a195bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the kfold class from model_selection module\n",
    "kf = model_selection.KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93917fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the new kfold column\n",
    "for fold, (trn_, val_) in enumerate(kf.split(X=df)):\n",
    "    df.loc[val_, 'kfold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3c292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mfr</th>\n",
       "      <th>type</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>shelf</th>\n",
       "      <th>weight</th>\n",
       "      <th>cups</th>\n",
       "      <th>rating</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Fruitful Bran</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12</td>\n",
       "      <td>190</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>41.015492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Grape Nuts Flakes</td>\n",
       "      <td>P</td>\n",
       "      <td>C</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>52.076897</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wheat Chex</td>\n",
       "      <td>R</td>\n",
       "      <td>C</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>49.787445</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Muesli Raisins; Dates; &amp; Almonds</td>\n",
       "      <td>R</td>\n",
       "      <td>C</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>37.136863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Strawberry Fruit Wheats</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59.363993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name mfr type  ...  cups     rating  kfold\n",
       "39                     Fruitful Bran   K    C  ...  0.67  41.015492      2\n",
       "57                 Grape Nuts Flakes   P    C  ...  0.88  52.076897      3\n",
       "46                        Wheat Chex   R    C  ...  0.67  49.787445      2\n",
       "51  Muesli Raisins; Dates; & Almonds   R    C  ...  1.00  37.136863      3\n",
       "76           Strawberry Fruit Wheats   N    C  ...  1.00  59.363993      4\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b00f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new csv with kfold column\n",
    "df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f90bb",
   "metadata": {},
   "source": [
    "### 2. Stratified k-fold\n",
    "\n",
    "- If you have a skewed dataset for binary classification with 90% positive samples and only 10% negative samples, prefer using stratified k-fold cross validation.\n",
    "- Stratified k-fold cross-validation keeps the ratio of labels in each fold constant.\n",
    "- We assume that our CSV dataset has a column called ‚Äútarget‚Äù and it is a classification problem!\n",
    "- If it‚Äôs a standard classification problem, choose stratified k-fold blindly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba6b221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
       "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
       "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
       "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
       "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
       "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"winequality-red.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "762a0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ca67e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "b = sns.countplot(x='quality', data=df1)\n",
    "b.set_xlabel(\"quality\", fontsize=20)\n",
    "b.set_ylabel(\"count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1055af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "df1 = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "df1[\"kfold\"] = -1\n",
    "\n",
    "df1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch targets\n",
    "y = df1.quality.values\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df1, y=y)):\n",
    "    df1.loc[v_, 'kfold'] = f\n",
    "\n",
    "df1.to_csv(\"train_folds1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17e40e",
   "metadata": {},
   "source": [
    "### 3. Hold-out based validation\n",
    "\n",
    "- If we have a large amount of data, we should use hold-out method\n",
    "- It is frequently used with time-series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8f715",
   "metadata": {},
   "source": [
    "### 4. Leave-one-out\n",
    "\n",
    "- For small datasets, using a large validation set reduces the training data too much.\n",
    "- A solution is Leave-One-Out Cross-Validation (LOOCV), where:\n",
    "    1. ùëò = ùëÅ i.e., the number of folds equals the number of samples.\n",
    "    2. Each fold trains on all samples except one, which is used for validation.\n",
    "- This ensures maximum use of data for training in every fold.\n",
    "- Drawback: can be computationally expensive if the model is slow.\n",
    "- But since it‚Äôs applied mainly to small datasets, the time cost is usually acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07eea7",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "* For **regression problems**, most cross-validation techniques (e.g., k-fold, LOOCV) can be used.\n",
    "* **Stratified k-fold** is not directly applicable to regression.\n",
    "* To use stratified k-fold in regression:\n",
    "\n",
    "  * **Bin the target values** into discrete intervals.\n",
    "  * Apply stratified k-fold as in classification.\n",
    "* Choosing number of bins:\n",
    "\n",
    "  * For **large datasets** (>10k or >100k samples): use \\~10‚Äì20 bins (exact choice doesn‚Äôt matter much).\n",
    "  * For **smaller datasets**, use **Sturge‚Äôs Rule**:\n",
    "\n",
    "    $$\n",
    "    \\text{Number of Bins} = 1 + \\log_2(N)\n",
    "    $$\n",
    "\n",
    "    where $N$ = number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05219104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified k-fold for regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "def create_folds(data):\n",
    "    # we create a new column kfold and fill it with -1\n",
    "    data[\"kfold\"] = -1\n",
    "\n",
    "    # randomize the rows of the data\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # calculate the number of bins by Sturge's law\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "\n",
    "    # bin targets\n",
    "    data.loc[:, \"bins\"] = pd.cut(\n",
    "        data[\"target\"], bins=num_bins, labels=False\n",
    "    )\n",
    "\n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # fill the new kfold column\n",
    "    # note that instead of target values, we are using bins\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y = data.bins.values)):\n",
    "        data.loc[v_, \"kfold\"] = f\n",
    "\n",
    "    # drop the bins column\n",
    "    data = data.drop(\"bins\", axis = 1)\n",
    "\n",
    "    # return the dataframe with folds\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e6ef635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a sample dataset with 15k rows, 100 features and 1 target\n",
    "X, y = datasets.make_regression(\n",
    "    n_samples=15000, n_features=100, n_targets=1\n",
    ")\n",
    "\n",
    "# Create a dataframe out of our numpy arrays\n",
    "df = pd.DataFrame(\n",
    "    X,\n",
    "    columns = [f\"f_{i}\" for i in range(X.shape[1])]\n",
    ")\n",
    "\n",
    "df.loc[:, \"target\"] = y\n",
    "\n",
    "# create folds\n",
    "df = create_folds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60b99225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_27</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>f_31</th>\n",
       "      <th>f_32</th>\n",
       "      <th>f_33</th>\n",
       "      <th>f_34</th>\n",
       "      <th>f_35</th>\n",
       "      <th>f_36</th>\n",
       "      <th>f_37</th>\n",
       "      <th>f_38</th>\n",
       "      <th>f_39</th>\n",
       "      <th>...</th>\n",
       "      <th>f_62</th>\n",
       "      <th>f_63</th>\n",
       "      <th>f_64</th>\n",
       "      <th>f_65</th>\n",
       "      <th>f_66</th>\n",
       "      <th>f_67</th>\n",
       "      <th>f_68</th>\n",
       "      <th>f_69</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "      <th>f_80</th>\n",
       "      <th>f_81</th>\n",
       "      <th>f_82</th>\n",
       "      <th>f_83</th>\n",
       "      <th>f_84</th>\n",
       "      <th>f_85</th>\n",
       "      <th>f_86</th>\n",
       "      <th>f_87</th>\n",
       "      <th>f_88</th>\n",
       "      <th>f_89</th>\n",
       "      <th>f_90</th>\n",
       "      <th>f_91</th>\n",
       "      <th>f_92</th>\n",
       "      <th>f_93</th>\n",
       "      <th>f_94</th>\n",
       "      <th>f_95</th>\n",
       "      <th>f_96</th>\n",
       "      <th>f_97</th>\n",
       "      <th>f_98</th>\n",
       "      <th>f_99</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>-1.100333</td>\n",
       "      <td>1.596506</td>\n",
       "      <td>-0.447240</td>\n",
       "      <td>-0.155339</td>\n",
       "      <td>0.768688</td>\n",
       "      <td>-1.140359</td>\n",
       "      <td>-1.315275</td>\n",
       "      <td>0.729229</td>\n",
       "      <td>-0.481205</td>\n",
       "      <td>0.099111</td>\n",
       "      <td>-1.157138</td>\n",
       "      <td>1.522265</td>\n",
       "      <td>0.118098</td>\n",
       "      <td>-1.694440</td>\n",
       "      <td>-0.778429</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>-0.638231</td>\n",
       "      <td>-1.537185</td>\n",
       "      <td>2.064234</td>\n",
       "      <td>-0.638144</td>\n",
       "      <td>-0.401401</td>\n",
       "      <td>0.373256</td>\n",
       "      <td>1.371591</td>\n",
       "      <td>0.645987</td>\n",
       "      <td>-2.550386</td>\n",
       "      <td>-0.616242</td>\n",
       "      <td>0.213977</td>\n",
       "      <td>-2.115246</td>\n",
       "      <td>1.206391</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>-0.624705</td>\n",
       "      <td>-1.090417</td>\n",
       "      <td>0.674502</td>\n",
       "      <td>-1.210571</td>\n",
       "      <td>1.638903</td>\n",
       "      <td>0.153462</td>\n",
       "      <td>0.051586</td>\n",
       "      <td>0.886169</td>\n",
       "      <td>-1.634777</td>\n",
       "      <td>0.525817</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352119</td>\n",
       "      <td>-0.636709</td>\n",
       "      <td>0.442178</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>-0.365221</td>\n",
       "      <td>2.329040</td>\n",
       "      <td>0.046826</td>\n",
       "      <td>1.720009</td>\n",
       "      <td>0.778567</td>\n",
       "      <td>0.360709</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>-1.595084</td>\n",
       "      <td>-0.067112</td>\n",
       "      <td>-0.317940</td>\n",
       "      <td>0.798776</td>\n",
       "      <td>3.403532</td>\n",
       "      <td>-0.835296</td>\n",
       "      <td>0.427874</td>\n",
       "      <td>0.363404</td>\n",
       "      <td>-1.217224</td>\n",
       "      <td>0.640413</td>\n",
       "      <td>-0.484853</td>\n",
       "      <td>-0.837461</td>\n",
       "      <td>1.118377</td>\n",
       "      <td>-0.940739</td>\n",
       "      <td>-1.342685</td>\n",
       "      <td>-0.293663</td>\n",
       "      <td>1.895739</td>\n",
       "      <td>1.091888</td>\n",
       "      <td>0.248871</td>\n",
       "      <td>0.525043</td>\n",
       "      <td>-0.468064</td>\n",
       "      <td>0.139095</td>\n",
       "      <td>0.525301</td>\n",
       "      <td>1.560743</td>\n",
       "      <td>1.191666</td>\n",
       "      <td>-1.460764</td>\n",
       "      <td>-0.879890</td>\n",
       "      <td>250.967893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>-0.458971</td>\n",
       "      <td>-0.514250</td>\n",
       "      <td>-0.384236</td>\n",
       "      <td>1.303537</td>\n",
       "      <td>0.408554</td>\n",
       "      <td>-0.303840</td>\n",
       "      <td>0.689435</td>\n",
       "      <td>-1.521482</td>\n",
       "      <td>1.486747</td>\n",
       "      <td>-0.027605</td>\n",
       "      <td>0.029527</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.304340</td>\n",
       "      <td>0.348113</td>\n",
       "      <td>0.706906</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>-1.849421</td>\n",
       "      <td>0.684133</td>\n",
       "      <td>-0.200627</td>\n",
       "      <td>-0.052160</td>\n",
       "      <td>-1.383014</td>\n",
       "      <td>0.672471</td>\n",
       "      <td>-0.069973</td>\n",
       "      <td>-0.387445</td>\n",
       "      <td>-0.690331</td>\n",
       "      <td>0.769790</td>\n",
       "      <td>-1.045584</td>\n",
       "      <td>1.674893</td>\n",
       "      <td>-0.138707</td>\n",
       "      <td>0.559123</td>\n",
       "      <td>-1.333578</td>\n",
       "      <td>-0.675797</td>\n",
       "      <td>0.442530</td>\n",
       "      <td>1.341092</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>-1.432721</td>\n",
       "      <td>-0.037735</td>\n",
       "      <td>-0.742625</td>\n",
       "      <td>1.840400</td>\n",
       "      <td>-1.698349</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131351</td>\n",
       "      <td>1.770645</td>\n",
       "      <td>0.683084</td>\n",
       "      <td>0.342366</td>\n",
       "      <td>-0.882764</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>1.608211</td>\n",
       "      <td>2.003011</td>\n",
       "      <td>-0.312170</td>\n",
       "      <td>-0.377720</td>\n",
       "      <td>0.839849</td>\n",
       "      <td>-0.625976</td>\n",
       "      <td>1.124728</td>\n",
       "      <td>-0.169126</td>\n",
       "      <td>0.586660</td>\n",
       "      <td>-0.318102</td>\n",
       "      <td>-1.188295</td>\n",
       "      <td>0.885947</td>\n",
       "      <td>-0.781772</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.419159</td>\n",
       "      <td>-0.598293</td>\n",
       "      <td>2.037924</td>\n",
       "      <td>0.731487</td>\n",
       "      <td>-0.716807</td>\n",
       "      <td>0.510548</td>\n",
       "      <td>-2.491185</td>\n",
       "      <td>-0.867057</td>\n",
       "      <td>-0.301303</td>\n",
       "      <td>1.010110</td>\n",
       "      <td>-0.453490</td>\n",
       "      <td>-0.068894</td>\n",
       "      <td>0.751855</td>\n",
       "      <td>0.358542</td>\n",
       "      <td>-1.722401</td>\n",
       "      <td>-1.092141</td>\n",
       "      <td>0.766122</td>\n",
       "      <td>0.683955</td>\n",
       "      <td>-201.704817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14572</th>\n",
       "      <td>1.881563</td>\n",
       "      <td>1.641880</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.802686</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.995774</td>\n",
       "      <td>0.128104</td>\n",
       "      <td>1.443934</td>\n",
       "      <td>1.389210</td>\n",
       "      <td>0.261312</td>\n",
       "      <td>1.523943</td>\n",
       "      <td>1.578040</td>\n",
       "      <td>2.121570</td>\n",
       "      <td>0.106060</td>\n",
       "      <td>0.889536</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>0.292817</td>\n",
       "      <td>-0.350937</td>\n",
       "      <td>-0.352299</td>\n",
       "      <td>-1.184277</td>\n",
       "      <td>-0.234141</td>\n",
       "      <td>1.415409</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>-1.458919</td>\n",
       "      <td>-2.069726</td>\n",
       "      <td>-1.459200</td>\n",
       "      <td>-1.069537</td>\n",
       "      <td>0.712625</td>\n",
       "      <td>1.599857</td>\n",
       "      <td>-0.278087</td>\n",
       "      <td>-0.040440</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>-0.405954</td>\n",
       "      <td>-0.464185</td>\n",
       "      <td>-0.159533</td>\n",
       "      <td>1.791862</td>\n",
       "      <td>-0.230057</td>\n",
       "      <td>0.259606</td>\n",
       "      <td>-2.373634</td>\n",
       "      <td>1.481068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664664</td>\n",
       "      <td>-0.302547</td>\n",
       "      <td>-0.961745</td>\n",
       "      <td>1.172020</td>\n",
       "      <td>-1.035984</td>\n",
       "      <td>1.671667</td>\n",
       "      <td>-1.250874</td>\n",
       "      <td>-0.542648</td>\n",
       "      <td>-1.639854</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>0.405758</td>\n",
       "      <td>0.759954</td>\n",
       "      <td>-0.108705</td>\n",
       "      <td>-0.083798</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.720012</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>-1.801485</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.304377</td>\n",
       "      <td>-0.245528</td>\n",
       "      <td>1.108795</td>\n",
       "      <td>1.634221</td>\n",
       "      <td>0.925363</td>\n",
       "      <td>-1.167001</td>\n",
       "      <td>-3.189395</td>\n",
       "      <td>0.634477</td>\n",
       "      <td>0.205002</td>\n",
       "      <td>0.240518</td>\n",
       "      <td>-0.465929</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>-0.102788</td>\n",
       "      <td>-0.808238</td>\n",
       "      <td>-0.292347</td>\n",
       "      <td>-0.892096</td>\n",
       "      <td>0.583068</td>\n",
       "      <td>-1.342252</td>\n",
       "      <td>101.945957</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>0.544669</td>\n",
       "      <td>0.582327</td>\n",
       "      <td>0.515926</td>\n",
       "      <td>-0.985165</td>\n",
       "      <td>1.745819</td>\n",
       "      <td>-0.340498</td>\n",
       "      <td>0.640689</td>\n",
       "      <td>-1.438467</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.092889</td>\n",
       "      <td>2.656795</td>\n",
       "      <td>0.075372</td>\n",
       "      <td>0.898241</td>\n",
       "      <td>-0.401449</td>\n",
       "      <td>-0.607598</td>\n",
       "      <td>0.315249</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>-1.461689</td>\n",
       "      <td>1.212348</td>\n",
       "      <td>0.529926</td>\n",
       "      <td>-0.225195</td>\n",
       "      <td>-0.580717</td>\n",
       "      <td>-1.464553</td>\n",
       "      <td>-0.892287</td>\n",
       "      <td>2.353919</td>\n",
       "      <td>-0.109732</td>\n",
       "      <td>-0.301396</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.342370</td>\n",
       "      <td>1.620593</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>-1.148802</td>\n",
       "      <td>-0.541117</td>\n",
       "      <td>0.765927</td>\n",
       "      <td>-1.216618</td>\n",
       "      <td>-2.072983</td>\n",
       "      <td>0.724252</td>\n",
       "      <td>-1.884006</td>\n",
       "      <td>-0.429297</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.450153</td>\n",
       "      <td>-0.686152</td>\n",
       "      <td>-1.144495</td>\n",
       "      <td>-0.532931</td>\n",
       "      <td>1.725963</td>\n",
       "      <td>0.443773</td>\n",
       "      <td>0.984007</td>\n",
       "      <td>-0.792249</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>-0.728175</td>\n",
       "      <td>-0.202733</td>\n",
       "      <td>-0.187812</td>\n",
       "      <td>1.574468</td>\n",
       "      <td>0.278324</td>\n",
       "      <td>0.339749</td>\n",
       "      <td>-0.852040</td>\n",
       "      <td>1.438875</td>\n",
       "      <td>0.397536</td>\n",
       "      <td>-1.473282</td>\n",
       "      <td>-0.649861</td>\n",
       "      <td>1.492846</td>\n",
       "      <td>-0.842736</td>\n",
       "      <td>0.205499</td>\n",
       "      <td>-0.657495</td>\n",
       "      <td>-1.237852</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0.578019</td>\n",
       "      <td>0.835565</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>-0.422448</td>\n",
       "      <td>-0.084698</td>\n",
       "      <td>0.640405</td>\n",
       "      <td>1.394657</td>\n",
       "      <td>1.805651</td>\n",
       "      <td>0.602318</td>\n",
       "      <td>-1.214704</td>\n",
       "      <td>0.765632</td>\n",
       "      <td>292.768364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12872</th>\n",
       "      <td>-1.025454</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>-0.232552</td>\n",
       "      <td>0.292508</td>\n",
       "      <td>0.436781</td>\n",
       "      <td>-1.688212</td>\n",
       "      <td>0.251557</td>\n",
       "      <td>-0.374332</td>\n",
       "      <td>-1.247372</td>\n",
       "      <td>0.604061</td>\n",
       "      <td>2.877468</td>\n",
       "      <td>0.307691</td>\n",
       "      <td>-0.282995</td>\n",
       "      <td>0.442286</td>\n",
       "      <td>-0.723925</td>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.041811</td>\n",
       "      <td>1.203674</td>\n",
       "      <td>-0.186925</td>\n",
       "      <td>2.266892</td>\n",
       "      <td>0.573856</td>\n",
       "      <td>-0.735313</td>\n",
       "      <td>1.449141</td>\n",
       "      <td>0.645452</td>\n",
       "      <td>0.593594</td>\n",
       "      <td>0.503474</td>\n",
       "      <td>-1.322764</td>\n",
       "      <td>0.087908</td>\n",
       "      <td>0.235184</td>\n",
       "      <td>0.297575</td>\n",
       "      <td>0.859857</td>\n",
       "      <td>1.063354</td>\n",
       "      <td>-1.676181</td>\n",
       "      <td>1.313912</td>\n",
       "      <td>-0.108696</td>\n",
       "      <td>0.649976</td>\n",
       "      <td>-0.014337</td>\n",
       "      <td>-0.177792</td>\n",
       "      <td>0.602186</td>\n",
       "      <td>1.179113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663608</td>\n",
       "      <td>1.295036</td>\n",
       "      <td>-1.643778</td>\n",
       "      <td>1.045890</td>\n",
       "      <td>-0.530189</td>\n",
       "      <td>-1.094867</td>\n",
       "      <td>0.679302</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.606455</td>\n",
       "      <td>-1.111221</td>\n",
       "      <td>-0.976514</td>\n",
       "      <td>0.480518</td>\n",
       "      <td>-1.597730</td>\n",
       "      <td>1.401430</td>\n",
       "      <td>-0.541795</td>\n",
       "      <td>0.737370</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>-0.464668</td>\n",
       "      <td>0.809975</td>\n",
       "      <td>-0.574985</td>\n",
       "      <td>0.088717</td>\n",
       "      <td>-0.968138</td>\n",
       "      <td>-1.783125</td>\n",
       "      <td>2.581419</td>\n",
       "      <td>0.616056</td>\n",
       "      <td>-0.899189</td>\n",
       "      <td>0.462632</td>\n",
       "      <td>1.094940</td>\n",
       "      <td>-0.854982</td>\n",
       "      <td>0.401731</td>\n",
       "      <td>-0.847183</td>\n",
       "      <td>0.916269</td>\n",
       "      <td>1.058834</td>\n",
       "      <td>-0.562958</td>\n",
       "      <td>-0.138548</td>\n",
       "      <td>-1.023088</td>\n",
       "      <td>0.495743</td>\n",
       "      <td>-1.122807</td>\n",
       "      <td>95.476814</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_0       f_1       f_2  ...      f_99      target  kfold\n",
       "4860  -1.100333  1.596506 -0.447240  ... -0.879890  250.967893      1\n",
       "1289  -0.458971 -0.514250 -0.384236  ...  0.683955 -201.704817      0\n",
       "14572  1.881563  1.641880  0.068960  ... -1.342252  101.945957      4\n",
       "3183   0.544669  0.582327  0.515926  ...  0.765632  292.768364      1\n",
       "12872 -1.025454  0.052576 -0.232552  ... -1.122807   95.476814      4\n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1701b2",
   "metadata": {},
   "source": [
    "* **Cross-validation** is the first and most essential step in building ML models.\n",
    "* Always **split your data first** before:\n",
    "\n",
    "  * Doing feature engineering\n",
    "  * Training models\n",
    "* A **good cross-validation scheme** ensures validation data is representative of both training and real-world data.\n",
    "* Proper cross-validation leads to models that are **highly generalizable**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f1e85",
   "metadata": {},
   "source": [
    "### 5. group k-fold\n",
    "\n",
    "* Suppose we are building a **binary classifier** to detect skin cancer (benign vs malignant) from patient images.\n",
    "* Problem: the dataset may have **multiple images per patient**.\n",
    "* If we split data randomly, the **same patient could appear in both training and validation sets**, causing **data leakage**.\n",
    "* **GroupKFold** solves this by:\n",
    "\n",
    "  * Treating each **patient as a group**.\n",
    "  * Ensuring that **all images from one patient stay in the same fold**.\n",
    "  * This means a patient‚Äôs images are either entirely in training or entirely in validation, never both.\n",
    "* This makes the cross-validation more **realistic and reliable**, since the model is tested on unseen patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a0a83c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
